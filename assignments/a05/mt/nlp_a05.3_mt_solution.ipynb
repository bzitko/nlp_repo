{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "url_path = \"https://raw.githubusercontent.com/bzitko/nlp_repo/main/assignments/a05/mt/\"\n",
    "downloads = {\"eng_fra_simplest.csv\": None}\n",
    "\n",
    "for download_name, extract_name in downloads.items():\n",
    "    if extract_name and os.path.exists(extract_name):\n",
    "        continue\n",
    "\n",
    "    if not os.path.exists(download_name):\n",
    "        import requests\n",
    "        response = requests.get(f\"{url_path}{download_name}\")\n",
    "        with open(download_name, \"wb\") as fp:\n",
    "            fp.write(response.content)\n",
    "        response.close()\n",
    "\n",
    "    if not extract_name:\n",
    "        continue\n",
    "\n",
    "    _, ext = os.path.splitext(download_name)\n",
    "    if ext == \".bz2\":    \n",
    "        import bz2\n",
    "        with open(download_name, 'rb') as bzf, open(extract_name, 'wb') as fp:\n",
    "            fp.write(bz2.decompress(bzf.read()))\n",
    "    elif ext == \".zip\":\n",
    "        from zipfile import ZipFile\n",
    "        with ZipFile(download_name) as zf:\n",
    "            zf.extractall(path=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Translation English to French\n",
    "\n",
    "## 1 Preprocessing\n",
    "### 1.1 Imports and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from typing import List, Tuple\n",
    "import random\n",
    "\n",
    "# Dummy tokenizer (replace with your tokenizer)\n",
    "def tokenize(text: str) -> List[str]:\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Vocabulary\n",
    "\n",
    "This class defines a vocabulary for converting words into indices and vice versa. The `__init__` method initializes the vocabulary with special tokens for padding (`<pad>`), start of sentence (`<sos>`), end of sentence (`<eos>`), and unknown words (`<unk>`). It creates mappings between words and indices (`word2idx`) and vice versa (`idx2word`). The `indices_to_sentence` method converts a list of indices back into a sentence by mapping each index to the corresponding word, ignoring padding and special tokens like `<eos>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary class\n",
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.pad_idx = 0\n",
    "        self.sos_idx = 1\n",
    "        self.eos_idx = 2\n",
    "        self.unk_idx = 3\n",
    "\n",
    "        self.word2idx = {\"<pad>\": self.pad_idx, \n",
    "                         \"<sos>\": self.sos_idx, \n",
    "                         \"<eos>\": self.eos_idx, \n",
    "                         \"<unk>\": self.unk_idx}\n",
    "        \n",
    "        self.idx2word = {idx: word for word, idx in self.word2idx.items()}\n",
    "        \n",
    "    def indices_to_sentence(self, indices: List[int]) -> List[str]:\n",
    "        return [self.idx2word[idx] for idx in indices if idx not in (self.pad_idx, self.eos_idx, self.eos_idx)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëç Add each word in a tokenized sentence to the vocabulary, assigning it a unique index if it‚Äôs not already present.\n",
    "\n",
    "Implement `add_sentence` method. Loop through each word in the input `sentence`. If the word is not in `word2idx`, assign it the next available index using `len(self.word2idx)`, and add the word and its index to both `word2idx` and `idx2word`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sentence(self, sentence: List[str]):\n",
    "    for word in sentence:\n",
    "        if word not in self.word2idx:\n",
    "            idx = len(self.word2idx)\n",
    "            self.word2idx[word] = idx\n",
    "            self.idx2word[idx] = word\n",
    "\n",
    "Vocabulary.add_sentence = add_sentence\n",
    "\n",
    "# Initialize vocabulary\n",
    "vocab = Vocabulary()\n",
    "\n",
    "# Test 1: Adding a sentence\n",
    "sentence = [\"I\", \"am\", \"learning\"]\n",
    "vocab.add_sentence(sentence)\n",
    "assert \"I\" in vocab.word2idx, \"Test 1 failed: 'I' should be in word2idx.\"\n",
    "assert vocab.word2idx[\"I\"] == 4, \"Test 1 failed: Index for 'I' should be 4.\"\n",
    "\n",
    "# Test 2: Adding the same sentence again (no new words)\n",
    "vocab.add_sentence(sentence)\n",
    "assert len(vocab.word2idx) == 7, \"Test 2 failed: No new words should be added.\"\n",
    "\n",
    "# Test 3: Adding a new word\n",
    "sentence = [\"new\", \"word\"]\n",
    "vocab.add_sentence(sentence)\n",
    "assert \"new\" in vocab.word2idx, \"Test 3 failed: 'new' should be in word2idx.\"\n",
    "assert vocab.word2idx[\"new\"] == 7, \"Test 3 failed: Index for 'new' should be 7.\"\n",
    "\n",
    "# Test 4: Checking special tokens\n",
    "assert vocab.word2idx[\"<pad>\"] == 0, \"Test 4 failed: <pad> should have index 0.\"\n",
    "assert vocab.word2idx[\"<sos>\"] == 1, \"Test 4 failed: <sos> should have index 1.\"\n",
    "assert vocab.word2idx[\"<eos>\"] == 2, \"Test 4 failed: <eos> should have index 2.\"\n",
    "assert vocab.word2idx[\"<unk>\"] == 3, \"Test 4 failed: <unk> should have index 3.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëç Convert a tokenized sentence into a list of indices using the vocabulary, adding start-of-sequence (`<sos>`) at the beginning and end-of-sequence (`<eos>`) at the end.\n",
    "\n",
    "First, add the start-of-sequence index (`sos_idx`) at the beginning of the list. Then, for each word in the sentence, get its index from `word2idx`. If the word is not in the vocabulary, use the unknown word index (`unk_idx`). Finally, add the end-of-sequence index (`eos_idx`) at the end of the list and return the list of indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_indices(self, sentence: List[str]) -> List[int]:\n",
    "    return [self.sos_idx] + [self.word2idx.get(word, self.unk_idx) for word in sentence] + [self.eos_idx]\n",
    "\n",
    "Vocabulary.sentence_to_indices = sentence_to_indices\n",
    "\n",
    "# Initialize vocabulary and add some sentences\n",
    "vocab = Vocabulary()\n",
    "vocab.add_sentence([\"I\", \"am\", \"learning\"])\n",
    "vocab.add_sentence([\"I\", \"love\", \"coding\"])\n",
    "\n",
    "# Test 1: Converting a sentence to indices\n",
    "sentence = [\"I\", \"am\", \"learning\"]\n",
    "indices = vocab.sentence_to_indices(sentence)\n",
    "assert indices == [1, 4, 5, 6, 2], \"Test 1 failed: Incorrect indices.\"\n",
    "\n",
    "# Test 2: Handling an unknown word\n",
    "sentence = [\"I\", \"am\", \"sleeping\"]\n",
    "indices = vocab.sentence_to_indices(sentence)\n",
    "assert indices == [1, 4, 5, 3, 2], \"Test 2 failed: Incorrect indices with unknown word.\"\n",
    "\n",
    "# Test 3: Empty sentence\n",
    "sentence = []\n",
    "indices = vocab.sentence_to_indices(sentence)\n",
    "assert indices == [1, 2], \"Test 3 failed: Incorrect indices for empty sentence.\"\n",
    "\n",
    "# Test 4: Check special tokens\n",
    "assert vocab.sentence_to_indices([\"I\"]) == [1, 4, 2], \"Test 4 failed: Incorrect indices for sentence with a single word.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëç Convert a list of indices back into a sentence, excluding the special tokens `<pad>` and `<eos>`.\n",
    "\n",
    "For each index in the list of `indices`, look up the corresponding word in `idx2word`. Exclude the special tokens (`<pad>`, `<sos>` and `<eos>`) and return the resulting list of words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_to_sentence(self, indices: List[int]) -> List[str]:\n",
    "    return [self.idx2word[idx] for idx in indices if idx not in (self.pad_idx, self.sos_idx, self.eos_idx)]\n",
    "\n",
    "Vocabulary.indices_to_sentence = indices_to_sentence\n",
    "\n",
    "# Initialize vocabulary and add some sentences\n",
    "vocab = Vocabulary()\n",
    "vocab.add_sentence([\"I\", \"am\", \"learning\"])\n",
    "\n",
    "# Test 1: Convert indices back to sentence\n",
    "indices = [1, 4, 5, 6, 2]\n",
    "sentence = vocab.indices_to_sentence(indices)\n",
    "assert sentence == [\"I\", \"am\", \"learning\"], \"Test 1 failed: Incorrect sentence conversion.\"\n",
    "\n",
    "# Test 2: Handle indices with special tokens\n",
    "indices = [1, 4, 5, 3, 2]\n",
    "sentence = vocab.indices_to_sentence(indices)\n",
    "assert sentence == [\"I\", \"am\", \"<unk>\"], \"Test 2 failed: Incorrect sentence with unknown word.\"\n",
    "\n",
    "# Test 3: Handle empty indices\n",
    "indices = [1, 2]\n",
    "sentence = vocab.indices_to_sentence(indices)\n",
    "assert sentence == [], \"Test 3 failed: Incorrect sentence for empty indices.\"\n",
    "\n",
    "# Test 4: Exclude special tokens\n",
    "indices = [1, 4, 2, 0, 0]\n",
    "sentence = vocab.indices_to_sentence(indices)\n",
    "assert sentence == [\"I\"], \"Test 4 failed: Incorrect handling of <pad> token.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Dataset\n",
    "\n",
    "This class defines a custom dataset for machine translation. It takes pairs of source and target sentences, along with their respective vocabularies, to convert sentences into sequences of word indices. In the `__init__` method, it ensures the source and target sentences have the same length and then converts each sentence into indices using the vocabulary. The `__len__` method returns the total number of sentences, while `__getitem__` retrieves a source and target sentence pair (as tensors) based on an index. This class is used for loading data efficiently during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, source_sentences: List[str], target_sentences: List[str], \n",
    "                 src_vocab: Vocabulary, tgt_vocab: Vocabulary):\n",
    "        assert len(source_sentences) == len(target_sentences), \\\n",
    "            \"Source and target sentences must contain same number of sentences.\"\n",
    "        self.src_sentences = [src_vocab.sentence_to_indices(tokenize(sentence)) \n",
    "                              for sentence in source_sentences]\n",
    "        self.tgt_sentences = [tgt_vocab.sentence_to_indices(tokenize(sentence)) \n",
    "                              for sentence in target_sentences]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_sentences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.src_sentences[idx]), torch.tensor(self.tgt_sentences[idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Model\n",
    "### 2.1 Encoder\n",
    "\n",
    "üëç Process a sequence of input indices through the embedding layer and the GRU RNN layer, then return the hidden state from the RNN.\n",
    "\n",
    "Implement `forward` method. First, pass the input sequence (`src`) through the embedding layer to obtain embeddings. Then, feed these embeddings into the GRU to obtain the RNN's outputs and hidden state. Return the hidden state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, hidden_dim, n_layers):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embed_dim)\n",
    "        self.rnn = nn.GRU(embed_dim, hidden_dim, n_layers, batch_first=True)\n",
    "    \n",
    "    def forward(self, src):\n",
    "        embedded = self.embedding(src)\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        return hidden\n",
    "    \n",
    "\n",
    "# Initialize vocabulary, EncoderRNN, and input\n",
    "vocab = Vocabulary()\n",
    "vocab.add_sentence([\"I\", \"am\", \"learning\"])\n",
    "\n",
    "encoder = EncoderRNN(input_dim=len(vocab.word2idx), embed_dim=8, hidden_dim=16, n_layers=2)\n",
    "src = torch.tensor([1, 4, 5, 6, 2]).unsqueeze(0)  # Example input sequence (batch size 1)\n",
    "\n",
    "# Test 1: Check the shape of hidden state returned by the forward pass\n",
    "hidden = encoder(src)\n",
    "assert hidden.shape == (2, 1, 16), \"Test 1 failed: Hidden state shape is incorrect.\"\n",
    "\n",
    "# Test 2: Check if the output is a tensor\n",
    "assert isinstance(hidden, torch.Tensor), \"Test 2 failed: Output should be a torch tensor.\"\n",
    "\n",
    "# Test 3: Check the hidden state for different input sequences\n",
    "src_2 = torch.tensor([1, 3, 2]).unsqueeze(0)\n",
    "hidden_2 = encoder(src_2)\n",
    "assert hidden_2.shape == (2, 1, 16), \"Test 3 failed: Hidden state shape is incorrect for different input.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Decoder\n",
    "\n",
    "üëç Process a target sequence (`tgt`) through the embedding layer, pass it through the GRU layer using the given hidden state, and generate predictions using the output of the GRU layer.\n",
    "\n",
    "Implement `forward` method. First, pass the target sequence (`tgt`) through the embedding layer to get the embeddings. Then, pass the embeddings and the hidden state through the GRU to get the RNN's outputs and updated hidden state. Finally, use a fully connected layer (`fc_out`) to make predictions from the GRU's outputs. Return both the predictions and the updated hidden state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, output_dim, embed_dim, hidden_dim, n_layers):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_dim, embed_dim)\n",
    "        self.rnn = nn.GRU(embed_dim, hidden_dim, n_layers, batch_first=True)\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, tgt, hidden):\n",
    "        embedded = self.embedding(tgt)\n",
    "        outputs, hidden = self.rnn(embedded, hidden)\n",
    "        predictions = self.fc_out(outputs)\n",
    "        return predictions, hidden\n",
    "\n",
    "\n",
    "# Initialize vocabulary, DecoderRNN, and input\n",
    "vocab = Vocabulary()\n",
    "vocab.add_sentence([\"I\", \"am\", \"learning\"])\n",
    "decoder = DecoderRNN(output_dim=len(vocab.word2idx), embed_dim=8, hidden_dim=16, n_layers=2)\n",
    "tgt = torch.tensor([1, 4, 5, 6, 2]).unsqueeze(0)  # Example target sequence (batch size 1)\n",
    "hidden = torch.zeros(2, 1, 16)  # Initial hidden state (num layers 2, batch size 1, hidden_dim 16)\n",
    "\n",
    "# Test 1: Check the shape of predictions and hidden state returned by the forward pass\n",
    "predictions, hidden_out = decoder(tgt, hidden)\n",
    "assert predictions.shape == (1, 5, len(vocab.word2idx)), \"Test 1 failed: Predictions shape is incorrect.\"\n",
    "assert hidden_out.shape == (2, 1, 16), \"Test 1 failed: Hidden state shape is incorrect.\"\n",
    "\n",
    "# Test 2: Check if the output predictions are a tensor\n",
    "assert isinstance(predictions, torch.Tensor), \"Test 2 failed: Predictions should be a torch tensor.\"\n",
    "\n",
    "# Test 3: Ensure the hidden state is updated correctly\n",
    "assert hidden_out is not hidden, \"Test 3 failed: Hidden state should be updated after passing through GRU.\"\n",
    "\n",
    "# Test 4: Check for consistent output size with a different target sequence\n",
    "tgt_2 = torch.tensor([1, 3, 2]).unsqueeze(0)\n",
    "predictions_2, hidden_out_2 = decoder(tgt_2, hidden)\n",
    "assert predictions_2.shape == (1, 3, len(vocab.word2idx)), \"Test 4 failed: Predictions shape is incorrect for different target.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Sequence to Sequence\n",
    "\n",
    "üëç Process the source sequence (`src`) through the encoder and the target sequence (`tgt`) through the decoder, using the hidden state from the encoder. Return the decoder's output.\n",
    "\n",
    "Implement `forward` method. First, pass the source sequence (`src`) through the encoder to obtain the hidden state. Then, pass the target sequence (`tgt`) and the hidden state to the decoder. The decoder will output the predictions and the updated hidden state, but only the predictions should be returned by the `forward` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seq2Seq Model\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self, src, tgt):\n",
    "        hidden = self.encoder(src)\n",
    "        outputs, hidden = self.decoder(tgt, hidden)\n",
    "        return outputs\n",
    "    \n",
    "\n",
    "# Initialize vocabulary, EncoderRNN, DecoderRNN, and Seq2Seq model\n",
    "vocab = Vocabulary()\n",
    "vocab.add_sentence([\"I\", \"am\", \"learning\"])\n",
    "encoder = EncoderRNN(input_dim=len(vocab.word2idx), embed_dim=8, hidden_dim=16, n_layers=2)\n",
    "decoder = DecoderRNN(output_dim=len(vocab.word2idx), embed_dim=8, hidden_dim=16, n_layers=2)\n",
    "model = Seq2Seq(encoder, decoder)\n",
    "src = torch.tensor([1, 4, 5, 6, 2]).unsqueeze(0)  # Example source sequence (batch size 1)\n",
    "tgt = torch.tensor([1, 4, 5, 6, 2]).unsqueeze(0)  # Example target sequence (batch size 1)\n",
    "\n",
    "# Test 1: Check the shape of the outputs returned by the forward pass\n",
    "outputs = model(src, tgt)\n",
    "assert outputs.shape == (1, 5, len(vocab.word2idx)), \"Test 1 failed: Output shape is incorrect.\"\n",
    "\n",
    "# Test 2: Check if the output is a tensor\n",
    "assert isinstance(outputs, torch.Tensor), \"Test 2 failed: Output should be a torch tensor.\"\n",
    "\n",
    "# Test 3: Ensure the forward pass works with different sequences\n",
    "src_2 = torch.tensor([1, 3, 2]).unsqueeze(0)\n",
    "tgt_2 = torch.tensor([1, 3, 2]).unsqueeze(0)\n",
    "outputs_2 = model(src_2, tgt_2)\n",
    "assert outputs_2.shape == (1, 3, len(vocab.word2idx)), \"Test 3 failed: Output shape is incorrect for different sequence.\"\n",
    "\n",
    "# Test 4: Check the shape of the encoder hidden state with 2 layers\n",
    "hidden_2_layers = torch.zeros(2, 1, 16)  # Initial hidden state for 2 layers\n",
    "hidden = encoder(src)\n",
    "assert hidden.shape == (2, 1, 16), \"Test 4 failed: Hidden state shape is incorrect for 2 layers.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Train\n",
    "\n",
    "### 3.1 Data Initialization\n",
    "\n",
    "This code prepares the data for training a machine translation model. It first checks if CUDA (GPU support) is available for faster computation. Then, it defines a small dummy dataset with English and French sentences. Vocabulary objects are created for both the source (English) and target (French) languages, and words are added to the vocabularies using the `add_sentence` method. A `TranslationDataset` is created, which pairs the English and French sentences together. A DataLoader is used to load the data in batches, and a custom collate function is defined to pad the sentences to equal lengths, ensuring they can be processed in batches.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use CUDA if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Dummy corpus for demonstration purposes\n",
    "english_sentences = [\n",
    "    \"hello how are you\",\n",
    "    \"what is your name\",\n",
    "    \"I am learning machine translation\",\n",
    "    \"this is an example sentence\"\n",
    "]\n",
    "french_sentences = [\n",
    "    \"bonjour comment allez-vous\",\n",
    "    \"quel est votre nom\",\n",
    "    \"j'apprends la traduction automatique\",\n",
    "    \"c'est une phrase exemple\"\n",
    "]\n",
    "\n",
    "# Vocabulary and Dataset Preparation\n",
    "src_vocab = Vocabulary()\n",
    "tgt_vocab = Vocabulary()\n",
    "\n",
    "# Build vocabularies\n",
    "for sentence in english_sentences:\n",
    "    src_vocab.add_sentence(tokenize(sentence))\n",
    "for sentence in french_sentences:\n",
    "    tgt_vocab.add_sentence(tokenize(sentence))\n",
    "\n",
    "# Dataset\n",
    "dataset = TranslationDataset(english_sentences, french_sentences, src_vocab, tgt_vocab)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=lambda batch: collate_fn(batch, tgt_vocab))\n",
    "\n",
    "# Collate function to pad sequences\n",
    "def collate_fn(batch, tgt_vocab):\n",
    "    src_batch, tgt_batch = zip(*batch)\n",
    "    src_padded = nn.utils.rnn.pad_sequence(src_batch, batch_first=True, padding_value=src_vocab.pad_idx)\n",
    "    tgt_padded = nn.utils.rnn.pad_sequence(tgt_batch, batch_first=True, padding_value=tgt_vocab.pad_idx)\n",
    "    return src_padded, tgt_padded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Model initialization\n",
    "\n",
    "This code defines the hyperparameters and initializes the model for training. The hyperparameters include the input and output dimensions (based on the source and target vocabularies), the embedding dimension, hidden dimension, number of layers in the encoder and decoder, learning rate, and the number of epochs for training. The encoder and decoder models are created using the `EncoderRNN` and `DecoderRNN` classes, respectively, and combined into a sequence-to-sequence (`Seq2Seq`) model. The loss function used is cross-entropy, which ignores padding tokens in the target sequences, and the optimizer is Adam with a specified learning rate. The model and all components are moved to the available device (GPU or CPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "INPUT_DIM = len(src_vocab.word2idx)\n",
    "OUTPUT_DIM = len(tgt_vocab.word2idx)\n",
    "EMBED_DIM = 256\n",
    "HIDDEN_DIM = 512\n",
    "N_LAYERS = 2\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "# Encoder and Decoder\n",
    "encoder = EncoderRNN(INPUT_DIM, EMBED_DIM, HIDDEN_DIM, N_LAYERS).to(device)\n",
    "decoder = DecoderRNN(OUTPUT_DIM, EMBED_DIM, HIDDEN_DIM, N_LAYERS).to(device)\n",
    "model = Seq2Seq(encoder, decoder).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tgt_vocab.pad_idx)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Training\n",
    "\n",
    "The `train_model` function trains the model for a specified number of epochs. For each batch in the dataloader, it moves the source and target sequences to the device and resets gradients. It prepares the target sequence for teacher forcing by splitting it into `tgt_input` (used as input) and `tgt_output` (the expected output). After performing a forward pass through the model, the loss is calculated by comparing the predicted output with the actual target. The loss is backpropagated, and the optimizer updates the model‚Äôs parameters. The epoch loss is printed after each epoch.\n",
    "\n",
    "**Teacher forcing** is a technique used during the training of sequence-to-sequence models where the model is fed the true output (from the training data) at each step of the decoding process, rather than using its own previous predictions. This helps the model learn the correct sequence of outputs more quickly by reducing the accumulation of errors in long sequences.\n",
    "\n",
    "Consider a model translating an English sentence \"I am learning\" to French. During training:\n",
    "\n",
    "1. **Without teacher forcing**: The model predicts the first word (\"Je\") and then uses that prediction (\"Je\") as input to predict the next word (\"suis\"). However, if the first prediction is wrong, the error compounds, making it harder to predict subsequent words correctly.\n",
    "\n",
    "2. **With teacher forcing**: Instead of using the model's predicted word (\"Je\"), the true word (\"Je\") from the training data is given as input for predicting the next word (\"suis\"). This reduces errors because the model is always given the correct word during training, making learning faster and more stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model(model, dataloader, optimizer, criterion, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        for src, tgt in dataloader:\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Prepare inputs for teacher forcing\n",
    "            tgt_input = tgt[:, :-1]\n",
    "            tgt_output = tgt[:, 1:]\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(src, tgt_input)\n",
    "            outputs = outputs.reshape(-1, outputs.size(-1))\n",
    "            tgt_output = tgt_output.reshape(-1)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, tgt_output)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "# Run training\n",
    "train_model(model, dataloader, optimizer, criterion, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Test\n",
    "\n",
    "### 4.1 Translation\n",
    "\n",
    "üëç Implement the `prepare_input` function, which should take a sentence, tokenize it, convert the tokens into indices using the source vocabulary, and return a tensor of the indices. The tensor should have a batch dimension (i.e., the sentence should be wrapped in a list). Ensure the tensor is placed on the correct device (CPU or CUDA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(sentence, src_vocab, device):\n",
    "    tokens = tokenize(sentence)\n",
    "    src_indices = src_vocab.sentence_to_indices(tokens)\n",
    "    src_tensor = torch.tensor([src_indices], dtype=torch.long, device=device)\n",
    "    return src_tensor\n",
    "\n",
    "# Create a mock source vocabulary\n",
    "src_vocab = Vocabulary()\n",
    "src_vocab.add_sentence(tokenize(\"hello how are you\"))\n",
    "\n",
    "# Prepare input sentence\n",
    "sentence = \"hello how are you\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "src_tensor = prepare_input(sentence, src_vocab, device)\n",
    "\n",
    "# Assert that the tensor has the correct shape and device\n",
    "assert src_tensor.shape == torch.Size([1, 6])  # batch size of 1, 6 tokens (2 special tokens)\n",
    "assert src_tensor.device == device  # Check that the tensor is on the correct device\n",
    "assert src_tensor[0, 0].item() == src_vocab.sos_idx  # First token should be <sos>\n",
    "assert src_tensor[0, -1].item() == src_vocab.eos_idx  # Last token should be <eos>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `encode_input` function takes the source sentence tensor (`src_tensor`), moves it to the specified device (CPU or GPU), and then passes it through the encoder of the model to get the hidden state. The `torch.no_grad()` context is used to disable gradient computation, as the function is used during inference (not training). The function then returns the hidden state generated by the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_input(model, src_tensor, device):\n",
    "    src_tensor = src_tensor.to(device)\n",
    "    with torch.no_grad():\n",
    "        hidden = model.encoder(src_tensor)\n",
    "    return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëç Implement the `decode_sentence` function, which decodes a sequence of tokens from the target vocabulary using a trained model. The function should start with the `<sos>` token, then iteratively predict the next token based on the model's outputs until either the maximum length is reached or the `<eos>` token is generated. The function should return a list of token indices.\n",
    "\n",
    "1. Initialize the target sequence with the `<sos>` token.\n",
    "2. For each step (up to `max_len`):\n",
    "   - Feed the current target sequence into the decoder.\n",
    "   - Get the decoder's output and hidden state.\n",
    "   - Predict the next token by taking the argmax of the output.\n",
    "   - Append the predicted token to the target sequence.\n",
    "   - Stop if the `<eos>` token is generated.\n",
    "3. Return the sequence of predicted target token indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sentence(model, tgt_vocab, hidden, max_len=50):\n",
    "    tgt_indices = [tgt_vocab.sos_idx]\n",
    "    for _ in range(max_len):\n",
    "        tgt_tensor = torch.tensor([tgt_indices], dtype=torch.long, device=device)\n",
    "        with torch.no_grad():\n",
    "            output, hidden = model.decoder(tgt_tensor, hidden)\n",
    "        next_token = output.argmax(2)[:, -1].item()\n",
    "        tgt_indices.append(next_token)\n",
    "        if next_token == tgt_vocab.eos_idx:\n",
    "            break\n",
    "    return tgt_indices\n",
    "\n",
    "# Prepare mock input for testing\n",
    "tgt_vocab = Vocabulary()\n",
    "tgt_vocab.add_sentence(tokenize(\"bonjour comment allez-vous\"))\n",
    "\n",
    "# Assume model is a pre-trained Seq2Seq model with an encoder and decoder\n",
    "# Assume 'hidden' is the hidden state from the encoder (mocked here for testing purposes)\n",
    "hidden = torch.zeros(2, 1, 512).to(device)  # Mock hidden state (num laters2, batch size 1, embedded dim)\n",
    "\n",
    "# Call the decode_sentence function\n",
    "tgt_indices = decode_sentence(model, tgt_vocab, hidden, max_len=10)\n",
    "\n",
    "# Assert that the output is a list of token indices and it ends with <eos>\n",
    "assert isinstance(tgt_indices, list)\n",
    "assert tgt_indices[-1] == tgt_vocab.eos_idx  # Should end with <eos> token\n",
    "assert len(tgt_indices) <= 10  # Should not exceed max_len\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `translate_indices_to_sentence` function takes a list of target token indices (`tgt_indices`) and converts them back into a sentence using the `tgt_vocab`. It excludes the `<sos>` token (since it's used only at the beginning) and returns the translated sentence as a string of words joined by spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_indices_to_sentence(tgt_indices, tgt_vocab):\n",
    "    translated_tokens = tgt_vocab.indices_to_sentence(tgt_indices[1:])  # Exclude <sos>\n",
    "    return \" \".join(translated_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `translate_sentence` function translates a given input sentence using the trained model. First, it prepares the input sentence by tokenizing and converting it into tensor format. Then, it encodes the input sentence using the model's encoder. Next, the sentence is decoded step by step to generate the output tokens. Finally, the generated token indices are converted back into a human-readable sentence. The function returns the translated sentence as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, model, src_vocab, tgt_vocab, device, max_len=50):\n",
    "    model.eval()\n",
    "    \n",
    "    # Step 1: Prepare input\n",
    "    src_tensor = prepare_input(sentence, src_vocab, device)\n",
    "\n",
    "    # Step 2: Encode input\n",
    "    hidden = encode_input(model, src_tensor, device)\n",
    "\n",
    "    # Step 3: Decode the sentence\n",
    "    tgt_indices = decode_sentence(model, tgt_vocab, hidden, max_len)\n",
    "\n",
    "    # Step 4: Convert indices to sentence\n",
    "    translated_sentence = translate_indices_to_sentence(tgt_indices, tgt_vocab)\n",
    "    \n",
    "    return translated_sentence\n",
    "\n",
    "\n",
    "source_sentence = \"hello how are you\"\n",
    "translated_sentence = translate_sentence(source_sentence, model, src_vocab, tgt_vocab, device)\n",
    "print(\"source sentence:\", sentence)\n",
    "print(\"translated sentence:\", translated_sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Evaluation\n",
    "\n",
    "This function evaluates the performance of a trained sequence-to-sequence model on a given dataset. It calculates the average loss and BLEU score across all sentences in the dataset. First, it performs a forward pass to compute the loss for each batch using the provided criterion. Then, for each sentence, it decodes the source sentence, compares the generated translation with the reference translation, and computes the BLEU score. Finally, it returns the average loss and average BLEU score for the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def evaluate_model(model, dataloader, criterion, src_vocab, tgt_vocab, device, max_len=50):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_bleu_score = 0\n",
    "    total_sentences = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in dataloader:\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "\n",
    "            # Prepare inputs for evaluation\n",
    "            tgt_input = tgt[:, :-1]\n",
    "            tgt_output = tgt[:, 1:]\n",
    "\n",
    "            # Forward pass to compute loss\n",
    "            outputs = model(src, tgt_input)\n",
    "            outputs = outputs.reshape(-1, outputs.size(-1))\n",
    "            tgt_output = tgt_output.reshape(-1)\n",
    "            loss = criterion(outputs, tgt_output)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Decode and compute BLEU score for each sentence\n",
    "            for i in range(src.size(0)):  # Loop over the batch\n",
    "                src_sentence = src[i]\n",
    "                tgt_sentence = tgt[i]\n",
    "                \n",
    "                # Decode source sentence\n",
    "                src_tokens = [src_vocab.idx2word[idx.item()] for idx in src_sentence if idx.item() != src_vocab.word2idx[\"<pad>\"]]\n",
    "                reference = [tgt_vocab.indices_to_sentence(tgt_sentence.cpu().numpy())]\n",
    "                hypothesis = translate_sentence(\" \".join(src_tokens), model, src_vocab, tgt_vocab, device, max_len).split()\n",
    "\n",
    "                # Compute BLEU score\n",
    "                total_bleu_score += sentence_bleu(reference, hypothesis)\n",
    "                total_sentences += 1\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_bleu_score = total_bleu_score / total_sentences\n",
    "    return avg_loss, avg_bleu_score\n",
    "\n",
    "\n",
    "# Example: Create a validation DataLoader\n",
    "validation_sentences = [\n",
    "    (\"hello how are you\", \"bonjour comment allez-vous\"),\n",
    "    (\"what is your name\", \"quel est votre nom\")\n",
    "]\n",
    "val_src_sentences, val_tgt_sentences = zip(*validation_sentences)\n",
    "\n",
    "validation_dataset = TranslationDataset(val_src_sentences, val_tgt_sentences, src_vocab, tgt_vocab)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=2, shuffle=False, collate_fn=lambda batch: collate_fn(batch, tgt_vocab))\n",
    "\n",
    "# Evaluate the model\n",
    "avg_loss, avg_bleu_score = evaluate_model(model, validation_dataloader, criterion, src_vocab, tgt_vocab, device)\n",
    "print(f\"Validation Loss: {avg_loss:.4f}\")\n",
    "print(f\"Average BLEU Score: {avg_bleu_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do Everythin on Larger Dataset\n",
    "\n",
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "machine_translation_df = pd.read_csv(\"eng_fra_simplest.csv\")\n",
    "\n",
    "train_df = machine_translation_df[machine_translation_df.split == \"train\"].drop(\"split\", axis=1).drop(machine_translation_df.columns[0], axis=1)\n",
    "val_df = machine_translation_df[machine_translation_df.split == \"val\"].drop(machine_translation_df.columns[0], axis=1)\n",
    "test_df = machine_translation_df[machine_translation_df.split == \"test\"].drop(machine_translation_df.columns[0], axis=1)\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_sentences = list(train_df.eng)\n",
    "french_sentences = list(train_df.fra)\n",
    "\n",
    "src_vocab = Vocabulary()\n",
    "tgt_vocab = Vocabulary()\n",
    "\n",
    "# Build vocabularies\n",
    "for sentence in english_sentences:\n",
    "    src_vocab.add_sentence(tokenize(sentence))\n",
    "for sentence in french_sentences:\n",
    "    tgt_vocab.add_sentence(tokenize(sentence))\n",
    "\n",
    "# Dataset\n",
    "BATCH_SIZE = 32\n",
    "dataset = TranslationDataset(english_sentences, french_sentences, src_vocab, tgt_vocab)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=lambda batch: collate_fn(batch, tgt_vocab))\n",
    "\n",
    "# Hyperparameters\n",
    "INPUT_DIM = len(src_vocab.word2idx)\n",
    "OUTPUT_DIM = len(tgt_vocab.word2idx)\n",
    "EMBED_DIM = 256\n",
    "HIDDEN_DIM = 512\n",
    "N_LAYERS = 2\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "# Encoder and Decoder\n",
    "encoder = EncoderRNN(INPUT_DIM, EMBED_DIM, HIDDEN_DIM, N_LAYERS).to(device)\n",
    "decoder = DecoderRNN(OUTPUT_DIM, EMBED_DIM, HIDDEN_DIM, N_LAYERS).to(device)\n",
    "model = Seq2Seq(encoder, decoder).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tgt_vocab.pad_idx)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Run training\n",
    "train_model(model, dataloader, optimizer, criterion, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "english_sentences = list(val_df.eng)\n",
    "french_sentences = list(val_df.fra)\n",
    "\n",
    "validation_dataset = TranslationDataset(english_sentences, french_sentences, src_vocab, tgt_vocab)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=2, shuffle=False, collate_fn=lambda batch: collate_fn(batch, tgt_vocab))\n",
    "\n",
    "# Evaluate the model\n",
    "avg_loss, avg_bleu_score = evaluate_model(model, validation_dataloader, criterion, src_vocab, tgt_vocab, device)\n",
    "print(f\"Validation Loss: {avg_loss:.4f}\")\n",
    "print(f\"Average BLEU Score: {avg_bleu_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "120px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": "5",
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
