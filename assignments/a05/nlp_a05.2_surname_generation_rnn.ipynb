{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surname generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "download_name = \"surnames_with_splits.csv.bz2\"\n",
    "if not os.path.exists(download_name):\n",
    "    import requests\n",
    "    response = requests.get(f\"https://raw.githubusercontent.com/bzitko/nlp_repo/main/lectures/a05/{download_name}\")\n",
    "    with open(download_name, \"wb\") as fp:\n",
    "        fp.write(response.content)\n",
    "    response.close()\n",
    "        \n",
    "name = \"surnames_with_splits.csv\"\n",
    "if not os.path.exists(name):\n",
    "    import bz2\n",
    "    with open(download_name, 'rb') as bzf, open(name, 'wb') as fp:\n",
    "        fp.write(bz2.decompress(bzf.read()))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from argparse import Namespace\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    # Data and path information\n",
    "    surname_csv=\"surnames_with_splits.csv\",\n",
    "    model_filename=\"model.pth\",\n",
    "    # Model hyper parameter\n",
    "    char_embedding_size=32,\n",
    "    rnn_hidden_size=32,\n",
    "    # Training hyper parameter\n",
    "    num_epochs=100,\n",
    "    learning_rate=0.001,\n",
    "    batch_size=128,\n",
    "    seed=1337,\n",
    "    early_stop=10,\n",
    "    # Runtime hyper parameter\n",
    ")\n",
    "\n",
    "args.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nationality</th>\n",
       "      <th>split</th>\n",
       "      <th>surname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>train</td>\n",
       "      <td>Totah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>train</td>\n",
       "      <td>Abboud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>train</td>\n",
       "      <td>Fakhoury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>train</td>\n",
       "      <td>Srour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>train</td>\n",
       "      <td>Sayegh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10975</th>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>test</td>\n",
       "      <td>Dinh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10976</th>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>test</td>\n",
       "      <td>Phung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10977</th>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>test</td>\n",
       "      <td>Quang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10978</th>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>test</td>\n",
       "      <td>Vu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10979</th>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>test</td>\n",
       "      <td>Ha</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10980 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      nationality  split   surname\n",
       "0          Arabic  train     Totah\n",
       "1          Arabic  train    Abboud\n",
       "2          Arabic  train  Fakhoury\n",
       "3          Arabic  train     Srour\n",
       "4          Arabic  train    Sayegh\n",
       "...           ...    ...       ...\n",
       "10975  Vietnamese   test      Dinh\n",
       "10976  Vietnamese   test     Phung\n",
       "10977  Vietnamese   test     Quang\n",
       "10978  Vietnamese   test        Vu\n",
       "10979  Vietnamese   test        Ha\n",
       "\n",
       "[10980 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(args.surname_csv).drop([\"nationality_index\"], axis=1)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary\n",
    "\n",
    "Generalized vocabulary can have:\n",
    "* padding token - to fill up empty space\n",
    "* unknown token - token for out-of-vocabulary tokens\n",
    "* begin sequence - token for start of a sequence\n",
    "* end sequence - token for end of a sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab(object):\n",
    "\n",
    "    def __init__(self, tokens=None, pad_token=None, unk_token=None, begin_seq_token=None, end_seq_token=None):\n",
    "        self._tok2idx = {}\n",
    "        self._idx2tok = {}\n",
    "        \n",
    "        self.pad_token = pad_token\n",
    "        self.pad_idx = None\n",
    "        if pad_token is not None:\n",
    "            self.pad_idx = self.add_token(pad_token)\n",
    "        \n",
    "        self.unk_token = unk_token\n",
    "        self.unk_idx = None\n",
    "        if unk_token is not None:\n",
    "            self.unk_idx = self.add_token(unk_token)\n",
    "\n",
    "        self.begin_seq_token = begin_seq_token\n",
    "        self.begin_seq_idx = None\n",
    "        if begin_seq_token is not None:\n",
    "            self.begin_seq_idx = self.add_token(begin_seq_token)\n",
    "\n",
    "        self.end_seq_token = end_seq_token\n",
    "        self.end_seq_idx = None\n",
    "        if end_seq_token is not None:\n",
    "            self.end_seq_idx = self.add_token(end_seq_token)\n",
    "\n",
    "        if tokens is not None:\n",
    "            self.add_tokens(tokens)\n",
    "\n",
    "    def add_token(self, token):\n",
    "        if token not in self._tok2idx:\n",
    "            idx = len(self._tok2idx)\n",
    "            self._tok2idx[token] = idx\n",
    "            self._idx2tok[idx] = token\n",
    "            return idx\n",
    "        return self._tok2idx[token]\n",
    "\n",
    "    def add_tokens(self, tokens):\n",
    "        return [self.add_token(token) for token in tokens]\n",
    "\n",
    "    def ordered_indices(self):\n",
    "        return sorted(self._idx2tok)\n",
    "\n",
    "    def ordered_tokens(self):\n",
    "        for i in sorted(self._idx2tok):\n",
    "            yield self._idx2tok[i]\n",
    "\n",
    "    def __getitem__(self, token_or_idx):\n",
    "        if isinstance(token_or_idx, str):\n",
    "            return self._tok2idx.get(token_or_idx, self.unk_idx)\n",
    "        if isinstance(token_or_idx, int):\n",
    "            return self._idx2tok.get(token_or_idx, self.unk_token)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._tok2idx)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for i in sorted(self._idx2tok):\n",
    "            yield self._idx2tok[i]\n",
    "\n",
    "    def info(self):\n",
    "        txt = f\"Vocabulary size:{len(self)}\"\n",
    "        for i in range(min(4, len(self))):\n",
    "            txt += f\" {self[i]}:{i}\"\n",
    "        txt += \" ...\"\n",
    "        print(txt)\n",
    "\n",
    "chars = {ch for surname in df[df.split == \"train\"].surname for ch in surname}\n",
    "surname_vocab = Vocab(sorted(chars), pad_token=\".\", unk_token=\"@\", begin_seq_token=\"<\", end_seq_token=\">\")\n",
    "nationality_vocab = Vocab(sorted(df.nationality))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizer\n",
    "\n",
    "* `vectorizer(tokens)` should return long tensor (vector). Vector values corresponds to tokens. Vector should be filled with padding indexes to satisfy vector maximal size.  \n",
    "\n",
    "* üëç  method `vectorize(tokens, seq=True)` receives \n",
    "    * `tokens` - a list of vocabulary entities, and\n",
    "    * `seq` - if set to true, then resulting vector represents a sequence.\n",
    "\n",
    "Let 0 is padding index, 2 is begin of sequence index and 3 is end of sequence index and maximal size is 10. Then for tokens whose indices are, for example, 56, 96 41, a resulting vector should be `[2 56 96 41 3 0 0 0 0]`.  \n",
    "If `seq` is set to false, resulting vector should be `[56 96 41 0 0 0 0 0 0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vectorizer():\n",
    "\n",
    "    def __init__(self, vocabulary, max_size=-1):\n",
    "        self.vocab = vocabulary\n",
    "        self.max_size = max_size\n",
    "\n",
    "    def vectorize(self, tokens, seq=True):\n",
    "        \n",
    "        return\n",
    "\n",
    "\n",
    "surname_max_size = max(len(surname) for surname in df.surname)\n",
    "surname_vectorizer = Vectorizer(surname_vocab, surname_max_size + 2)\n",
    "nationality_vectorizer = Vectorizer(nationality_vocab)\n",
    "\n",
    "assert nationality_vectorizer.vectorize([\"English\"], seq=False).tolist() == [4]\n",
    "assert surname_vectorizer.vectorize(\"johnson\", seq=True).tolist() == [ 2, 43, 48, 41, 47, 52, 48, 47,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "`SurnameDataset` class inherits `torch.utils.data.Dataset`.  \n",
    "Implemented methods are:\n",
    "* `__init__(df, vectorizer_x, vectorizer_h, nationalities)` initialization receives dataframe `df`, `vectorizer_x` vectorizer for surnames, and `vectorizer_h` for nationalities.\n",
    "* `set_split()` for setting current data split\n",
    "* üëç `__getitem__(idx)` should return triple of vectors: x, y, h where \n",
    "    * x is vectorized surname, for example `[2 56 96 41 3 0 0 0 0]`\n",
    "    * y is x moved to left, for example `[56 96 41 3 0 0 0 0 0]`\n",
    "    * h is vector for nationality\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurnameDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df, vectorizer_x, vectorizer_h, nationalities=None):\n",
    "        if nationalities is None:\n",
    "            self.df = df\n",
    "        elif isinstance(nationalities, str):\n",
    "            self.df = df[df.nationality == nationalities]\n",
    "        else:\n",
    "            self.df = df[df.nationality.isin(nationalities)]\n",
    "        self.vectorizer_x = vectorizer_x\n",
    "        self.vectorizer_h = vectorizer_h\n",
    "        self._lookup = {split: self.df[self.df.split == split] for split in set(self.df.split)}\n",
    "        self.set_split(\"train\")\n",
    "        \n",
    "    def set_split(self, split):\n",
    "        self._target_split = split\n",
    "        self._target_df = self._lookup[split]\n",
    "\n",
    "    def vectorize_x(self, surname):\n",
    "        return self.vectorizer_x.vectorize(surname, seq=True)\n",
    "\n",
    "    def vectorize_y(self, nationality):\n",
    "        return self.vectorizer_h.vectorize([nationality], seq=False).squeeze()\n",
    "\n",
    "\n",
    "    def frequency_x(self):\n",
    "        return torch.tensor([len(self.df[self.df.surname==tok]) for tok in self.vectorizer_x.vocab.ordered_tokens()])\n",
    "\n",
    "    def frequency_y(self):\n",
    "        return torch.tensor([len(self.df[self.df.nationality==tok]) for tok in self.vectorizer_h.vocab.ordered_tokens()])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self._target_df)\n",
    "\n",
    "    def get_num_batches(self, batch_size):\n",
    "        return len(self) // batch_size\n",
    "\n",
    "def generate_batches(dataset, batch_size, shuffle=True):\n",
    "    for x1, x2, y in torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle):\n",
    "        yield x1.to(args.device), x2.to(args.device), y.to(args.device)\n",
    "\n",
    "dataset = SurnameDataset(df, surname_vectorizer, nationality_vectorizer)\n",
    "\n",
    "assert len(dataset) == 7680\n",
    "assert len(dataset[0]) == 3\n",
    "\n",
    "dataset = SurnameDataset(df, surname_vectorizer, nationality_vectorizer, nationalities=\"English\")\n",
    "assert len(dataset) == 2080\n",
    "assert len(dataset[0]) == 3\n",
    "\n",
    "dataset = SurnameDataset(df, surname_vectorizer, nationality_vectorizer, nationalities=\"Russian\")\n",
    "assert len(dataset) == 1661\n",
    "assert len(dataset[0]) == 3\n",
    "\n",
    "dataset = SurnameDataset(df, surname_vectorizer, nationality_vectorizer, nationalities=[\"English\", \"Russian\"])\n",
    "assert len(dataset) == 3741\n",
    "assert len(dataset[0]) == 3\n",
    "\n",
    "\n",
    "dataset = SurnameDataset(df, surname_vectorizer, nationality_vectorizer)\n",
    "x, y, h = dataset[0]\n",
    "assert x.shape == y.shape\n",
    "assert x.tolist() == [2, 27, 48, 53, 34, 41, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "assert y.tolist()[:-1] == x.tolist()[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator\n",
    "\n",
    "üëç  \n",
    "`SurnameGenerator` initialization receives \n",
    "* `embedding_size` dimension of embedding vector (for surnames)\n",
    "* `num_embeddings` size of surname vocabulary\n",
    "* `rnn_hidden_size` dimension of hidden RNN layer\n",
    "* `num_rnn_hidden_embedding` size of nationality vocabulary\n",
    "* `dropout_p` probability of dropout\n",
    "\n",
    "Model will consist of: \n",
    "* $E_s$ - embedding layer for surnames, \n",
    "* $E_n$ - embedding layer for nationalities,\n",
    "* GRU - gated reccurent unit\n",
    "* FC - fully connected layer with dropout\n",
    "\n",
    "Forward receives \n",
    "* $x$ indicies of surnames\n",
    "* $h$ indicies of nationalityes\n",
    "\n",
    "then $\\hat{y} = FC(GRU(E_s(x), E_n(h)))$.\n",
    "\n",
    "Apply softmax if `apply_softmax` is set to true.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurnameGenerator(torch.nn.Module):\n",
    "    def __init__(self, embedding_size, num_embeddings, rnn_hidden_size, \n",
    "                 num_rnn_hidden_embedding=None, batch_first=True, padding_idx=0, dropout_p=0.5):\n",
    "        super(SurnameGenerator, self).__init__()\n",
    "\n",
    "\n",
    "    def forward(self, x, h=None, apply_softmax=False):\n",
    "        return\n",
    "        \n",
    "\n",
    "generator = SurnameGenerator(embedding_size=args.char_embedding_size, \n",
    "                             num_embeddings=len(dataset.vectorizer_x.vocab), \n",
    "                             rnn_hidden_size=args.rnn_hidden_size,\n",
    "                             num_rnn_hidden_embedding=len(dataset.vectorizer_h.vocab),\n",
    "                             batch_first=True,\n",
    "                             padding_idx=dataset.vectorizer_x.vocab.pad_idx)\n",
    "\n",
    "x1, x2, h = next(generate_batches(dataset, batch_size=3))\n",
    "y_hat = generator(x1)\n",
    "assert y_hat.shape == (3, 19, 80)\n",
    "\n",
    "y_hat = generator(x1, h)\n",
    "assert y_hat.shape == (3, 19, 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# accuracy\n",
    "def compute_accuracy(y_hat, y):\n",
    "    _, y_hat_indices = y_hat.max(dim=1)\n",
    "    n_correct = torch.eq(y_hat_indices, y).sum().item()\n",
    "    return n_correct / len(y_hat_indices) * 100\n",
    "\n",
    "# early stopping\n",
    "def early_stop(train_state, model):\n",
    "    val_loss = train_state[\"val_loss\"]\n",
    "    if len(val_loss) < 2:\n",
    "        torch.save(model.state_dict(), args.model_filename)\n",
    "        return False\n",
    "    \n",
    "    if val_loss[-1] < val_loss[-2]:\n",
    "        torch.save(model.state_dict(), args.model_filename)\n",
    "    \n",
    "    if len(val_loss) >= args.early_stop:\n",
    "        val_loss =  val_loss[-args.early_stop:]\n",
    "        return all(val_loss[i] < val_loss[i + 1] \n",
    "                   for i in range(args.early_stop - 1))\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining loss function\n",
    "\n",
    "For \n",
    "* $N$ - batch size\n",
    "* $C$ - sequence size\n",
    "* $V$ - vocabulary size\n",
    "\n",
    "let $\\hat{y}$ be a prediction tensor of shape $N \\times C \\times V$ and $y$ be a target tensor of shape $N \\times C$.  \n",
    "Function `compute_loss(y_hat, y)` is responsible for computing negative log-likelihood loss for each datapoint in the batch.\n",
    "\n",
    "Before applying pyTorch's NLLLoss, each sequence in the batch $\\hat{y}$ has to be turned into log of probabilities, i.e. $log(softmax(\\hat{y}_i))$ for $i=1...N$. After calculating all $N$ losses by $NLLLoss(log(softmax(\\hat{y}_i)), y_i)$ `compute_loss()` returns their mean.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.NLLLoss(ignore_index=0)\n",
    "\n",
    "def compute_loss(y_hat, y):\n",
    "    return\n",
    "\n",
    "batch_size = 3\n",
    "seq_size = 2\n",
    "vocab_size = 4\n",
    "\n",
    "torch.manual_seed(42)\n",
    "y_hat = torch.rand(batch_size, seq_size, vocab_size)\n",
    "y = torch.tensor([[0, 1], [2, 1], [3, 0]])\n",
    "loss = compute_loss(y_hat, y)\n",
    "assert torch.all(loss == torch.tensor(1.33540785))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     4
    ]
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(y_hat, y):\n",
    "    _, y_hat_indices = y_hat.max(dim=-1)\n",
    "    y_hat_indices = y_hat_indices.ravel()\n",
    "    y = y.ravel()\n",
    "    n_correct = torch.eq(y_hat_indices, y).sum().item()\n",
    "    return n_correct / len(y_hat_indices) * 100    \n",
    "\n",
    "# generator\n",
    "\n",
    "generator = SurnameGenerator(embedding_size=args.char_embedding_size, \n",
    "                             num_embeddings=len(dataset.vectorizer_x.vocab), \n",
    "                             rnn_hidden_size=args.rnn_hidden_size,\n",
    "                             num_rnn_hidden_embedding=len(dataset.vectorizer_h.vocab),\n",
    "                             batch_first=True,\n",
    "                             padding_idx=dataset.vectorizer_x.vocab.pad_idx)\n",
    "\n",
    "# seed\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "# loss, optimizer, scheduler\n",
    "loss_func = torch.nn.NLLLoss(ignore_index=dataset.vectorizer_x.vocab.pad_idx)\n",
    "optimizer = torch.optim.Adam(generator.parameters(), lr=args.learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', factor=0.5, patience=1)\n",
    "\n",
    "# progress bars\n",
    "epoch_bar = tqdm(desc='epochs', total=args.num_epochs, position=0)\n",
    "dataset.set_split('train')\n",
    "train_bar = tqdm(desc='train', total=dataset.get_num_batches(args.batch_size), position=1, leave=True)\n",
    "dataset.set_split('val')\n",
    "val_bar = tqdm(desc='val', total=dataset.get_num_batches(args.batch_size), position=1, leave=True)\n",
    "\n",
    "# train state tracker\n",
    "train_state = {\"train_loss\": [],\n",
    "               \"train_acc\": [],\n",
    "               \"val_loss\": [],\n",
    "               \"val_acc\": [],}\n",
    "\n",
    "\n",
    "generator = generator.to(args.device)\n",
    "try:\n",
    "    for epoch_index in range(args.num_epochs):\n",
    "        dataset.set_split('train')\n",
    "        batch_generator = generate_batches(dataset, batch_size=args.batch_size)\n",
    "        running_loss = running_acc = 0.0\n",
    "        \n",
    "        generator.train()\n",
    "        for batch_index, (x, y, h) in enumerate(batch_generator):\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = generator(x, h)\n",
    "            loss = compute_loss(y_hat, y)\n",
    "            loss_t = loss.item()\n",
    "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            acc_t = compute_accuracy(y_hat, y)\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "            # update bar\n",
    "            train_bar.set_postfix(loss=running_loss, acc=running_acc, epoch=epoch_index)\n",
    "            train_bar.update()\n",
    "\n",
    "        train_state['train_loss'].append(running_loss)\n",
    "        train_state['train_acc'].append(running_acc)        \n",
    "\n",
    "        # Iterate over val dataset\n",
    "        # setup: batch generator, set loss and acc to 0; set eval mode on\n",
    "        dataset.set_split('val')\n",
    "        batch_generator = generate_batches(dataset, batch_size=args.batch_size)\n",
    "        running_loss = running_acc = 0.0\n",
    "        \n",
    "        generator.eval()\n",
    "        for batch_index, (x, y, h) in enumerate(batch_generator):\n",
    "            y_hat =  generator(x, h)\n",
    "\n",
    "            loss = compute_loss(y_hat, y)\n",
    "            loss_t = loss.item()\n",
    "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "            acc_t = compute_accuracy(y_hat, y)\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "            # update bar\n",
    "            val_bar.set_postfix(loss=running_loss, acc=running_acc, epoch=epoch_index)\n",
    "            val_bar.update()\n",
    "\n",
    "        train_state['val_loss'].append(running_loss)\n",
    "        train_state['val_acc'].append(running_acc)   \n",
    "\n",
    "        if early_stop(train_state, generator):\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        scheduler.step(train_state['val_loss'][-1])\n",
    "\n",
    "        train_bar.n = 0\n",
    "        val_bar.n = 0\n",
    "        epoch_bar.update()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Exiting loop\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_state[\"val_loss\"])\n",
    "plt.plot(train_state[\"train_loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "generator.load_state_dict(torch.load(args.model_filename))\n",
    "\n",
    "generator = generator.to(args.device)\n",
    "loss_func = torch.nn.NLLLoss()\n",
    "\n",
    "dataset.set_split('test')\n",
    "batch_generator = generate_batches(dataset, batch_size=args.batch_size)\n",
    "\n",
    "running_loss = 0.\n",
    "running_acc = 0.\n",
    "\n",
    "generator.eval()\n",
    "for batch_index, (x, y, h) in enumerate(batch_generator):\n",
    "    y_hat =  generator(x, h)\n",
    "    \n",
    "    # compute the loss\n",
    "    loss = compute_loss(y_hat, y)\n",
    "    loss_t = loss.item()\n",
    "    running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "    # compute the accuracy\n",
    "    acc_t = compute_accuracy(y_hat, y)\n",
    "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "print(f\"Test loss: {running_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {running_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling\n",
    "\n",
    "Function `sample_from_model(model, vectorizer, num_samples=10, nationality_idx=None)` must generate `num_samples` surnames. If `nationality_idx` is set to some nationality index, then generated surnames belong to specific nationality. Nationality is represented as first hidden input $h_0$ to GRU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_model(model, vectorizer, num_samples=10, nationality_idx=None):\n",
    "    return []\n",
    "\n",
    "for nationality in nationality_vocab:\n",
    "    print(nationality)\n",
    "    samples = sample_from_model(generator, surname_vectorizer, num_samples=3, nationality_idx=nationality_vocab[nationality])\n",
    "    for sample in samples:\n",
    "        print(\" -\", sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2, svd_solver='full')\n",
    "\n",
    "emb = generator.emb.weight.data[1:,:]\n",
    "labels = list(surname_vocab.ordered_tokens())[1:]\n",
    "x = torch.tensor(pca.fit_transform(emb))\n",
    "\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.axis([torch.min(x).item(), torch.max(x).item(), torch.min(x).item(), torch.max(x).item()])\n",
    "for (xi, yi), lbl in zip(x, labels):\n",
    "    plt.text(xi, yi, lbl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "120px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": "5",
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "358f19b5168dcc2c817c22e8ae2c189228565b53de3b91095ee770a390daccdd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
