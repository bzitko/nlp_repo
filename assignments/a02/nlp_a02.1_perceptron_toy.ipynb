{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-CeYMXmbtG-"
   },
   "source": [
    "# Toy Data Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4290,
     "status": "ok",
     "timestamp": 1660203327038,
     "user": {
      "displayName": "Branko Žitko",
      "userId": "04777374732866690844"
     },
     "user_tz": -120
    },
    "id": "rxFKBmmEEoUA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import pandas as pd\n",
    "import torch\n",
    "import torch.nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve\n",
    "\n",
    "def reseed(seed=96):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Generating synthetic data\n",
    "\n",
    "Make function `generate_toydata()` that recieves:\n",
    "* `batch_size` - number of datapoints\n",
    "* `w` - multipliyer of linear function\n",
    "* `b` - offset of linear function\n",
    "\n",
    "and returns two vectors:\n",
    "* `X` of shape (batch_size, 2) containing 2D datapoints\n",
    "* `Y` if shape (batch_size,) containing targets.\n",
    "\n",
    "This function generates random batch size number of 2D points $(x_1, x_2)$ where:\n",
    "* $x_1$ are random numbers and\n",
    "* $x_2$ are random numbers multiplied by $w$ and to which $b$ is added.\n",
    "\n",
    "Target ($y$) of $(x_1, x_2)$ will be:\n",
    "* $1$ if $x_2 > w * x_1 + b$\n",
    "* else $0$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1660203330781,
     "user": {
      "displayName": "Branko Žitko",
      "userId": "04777374732866690844"
     },
     "user_tz": -120
    },
    "id": "4uqOaX-Ah7KZ",
    "outputId": "604915d7-0ba5-4184-b90f-2ea2351af4c7",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generate_toy_data(batch_size, w, b):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reseed(1337)\n",
    "temp = generate_toy_data(4, w=2, b=1)\n",
    "assert isinstance(temp, tuple) and len(temp) == 2\n",
    "assert torch.allclose(temp[0], torch.tensor([[0.0783, 1.4008], [0.4956, 1.0573], [0.6231, 2.1702], [0.4224, 2.3934]]), atol=1e-4)\n",
    "assert torch.equal(temp[1], torch.tensor([1., 0., 0., 1.]))\n",
    "del temp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Plotting data\n",
    "\n",
    "Create function `plot_toy_data()` which receives two vectors:\n",
    "* $X$ vector of n datapoints $(x_1, x_2)$\n",
    "* $Y$ vector of n targets\n",
    "\n",
    "This function plots 2D datapoints in blue if corresponding target value is 1, red if opposite.\n",
    "\n",
    "Generate 1000 synthetic data points where $w$ = 5 and $b$ = 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 862,
     "status": "ok",
     "timestamp": 1660203331637,
     "user": {
      "displayName": "Branko Žitko",
      "userId": "04777374732866690844"
     },
     "user_tz": -120
    },
    "id": "GWtzQBm6buPs",
    "outputId": "8853f233-648a-4f2b-ca9a-176416f0c69b"
   },
   "outputs": [],
   "source": [
    "def plot_toy_data(x_data, y_truth, perceptron=None):\n",
    "    blue = []\n",
    "    orange = []\n",
    "    black_blue = []\n",
    "    black_orange = []\n",
    "    if perceptron:\n",
    "        y_pred = perceptron(x_data).squeeze().detach()\n",
    "        y_pred = (y_pred > 0.5).float()\n",
    "    else:\n",
    "        y_pred = y_truth\n",
    "\n",
    "    for x_i, y_true_i, y_pred_i in zip(x_data, y_truth, y_pred):\n",
    "        \n",
    "        is_black = y_true_i != y_pred_i\n",
    "\n",
    "        if y_true_i == 1.:\n",
    "            if is_black:\n",
    "                black_blue.append(x_i)\n",
    "            else:\n",
    "                blue.append(x_i)\n",
    "        else:\n",
    "            if is_black:\n",
    "                black_orange.append(x_i)\n",
    "            else:\n",
    "                orange.append(x_i)\n",
    "    \n",
    "    if blue:\n",
    "        blue = np.stack(blue)\n",
    "        plt.scatter(blue[:,0], blue[:,1], marker=\".\", c=\"tab:blue\")\n",
    "    \n",
    "    if orange:\n",
    "        orange = np.stack(orange)\n",
    "        plt.scatter(orange[:,0], orange[:,1], marker=\".\", c=\"tab:red\")\n",
    "\n",
    "    if perceptron:\n",
    "        if black_blue:\n",
    "            black_blue = np.stack(black_blue)\n",
    "            plt.scatter(black_blue[:,0], black_blue[:,1], marker=\".\", c=\"black\")\n",
    "        if black_orange:\n",
    "            black_orange = np.stack(black_orange)\n",
    "            plt.scatter(black_orange[:,0], black_orange[:,1], marker=\".\", c=\"black\")\n",
    "\n",
    "        # hyperplane\n",
    "        xx = np.linspace(x_data[:,0].min(), x_data[:,0].max(), 30)\n",
    "        yy = np.linspace(x_data[:,1].min(), x_data[:,1].max(), 30)\n",
    "        xv, yv = np.meshgrid(xx, yy)\n",
    "        xy = np.vstack([xv.ravel(), yv.ravel()]).T\n",
    "        z = perceptron(torch.tensor(xy, dtype=torch.float)).detach().numpy().reshape(yv.shape)\n",
    "        \n",
    "        plt.contour(xx, yy, z, colors='k', linestyles=[\"--\", \"-\", \"--\"], levels=[0.4, 0.5, 0.6])\n",
    "    plt.show()\n",
    "\n",
    "plot_toy_data(*generate_toy_data(1024, w=5, b=3))\n",
    "# plot_toy_data(*get_toy_data(1024), perceptron)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1. Perceptron\n",
    "\n",
    "Create `Perceptron` class where perceptron receives 2 numbers and outputs 1 number.  \n",
    "Create `forward()` method which receives datapoint $(x_1, x_2)$ which is an input to perceptron and applies sigmoid on perceptron's output.  \n",
    "Create `predict()`method which receives datapoint $(x_1, x_2)$ and returns 1 if the result after forward is greater or equal 0.5, otherwise 0.  \n",
    "Create `reset()` method which resets parameters of the model (call `reset_parameter` on model layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1660203331638,
     "user": {
      "displayName": "Branko Žitko",
      "userId": "04777374732866690844"
     },
     "user_tz": -120
    },
    "id": "1IBXUdZFb22E",
    "outputId": "b0f05472-886c-4cb6-fc77-9fc0e8a7b70b"
   },
   "outputs": [],
   "source": [
    "class Perceptron(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x_in):\n",
    "        return \n",
    "    \n",
    "    def predict(self, x_in):\n",
    "        return \n",
    "    \n",
    "    def reset(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reseed(1337)\n",
    "temp = Perceptron()\n",
    "assert hasattr(temp, \"forward\") and hasattr(temp, \"predict\") and hasattr(temp, \"reset\")\n",
    "assert torch.allclose(temp(torch.FloatTensor([1, 2])), torch.tensor(0.3930), atol=1e-4)\n",
    "assert torch.allclose(temp(torch.FloatTensor([[1, 2], [3, 4]])), torch.tensor([0.3930, 0.1625]), atol=1e-4)\n",
    "assert torch.equal(temp.predict(torch.FloatTensor([1, 2])), torch.tensor(0.))\n",
    "assert torch.equal(temp.predict(torch.FloatTensor([[1, 2], [-5, 4]])), torch.tensor([0., 1.]))\n",
    "\n",
    "temp.reset()\n",
    "W, b = temp.parameters()\n",
    "assert torch.allclose(W, torch.tensor([-0.1097, -0.4237]), atol=1e-4) and torch.allclose(b, torch.tensor([-0.6666]), atol=1e-4)\n",
    "\n",
    "del temp, W, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set following variables:\n",
    "* learning rate `lr` to 0.01\n",
    "* `batch_size` = 1000\n",
    "* `W` = 90\n",
    "* `B` = 6\n",
    "\n",
    "Instantiate:\n",
    "* `model` as perceptron, \n",
    "* `optimizer`as adam optimizer with defined learning rate, \n",
    "* `loss_fn` as binary cross-entropy loss, \n",
    "\n",
    "Generate and remember static toy data with predefined parameters into `x_data_static` and `y_truth_static`.\n",
    "Plot toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 573,
     "status": "ok",
     "timestamp": 1660204001457,
     "user": {
      "displayName": "Branko Žitko",
      "userId": "04777374732866690844"
     },
     "user_tz": -120
    },
    "id": "6Aqr7DofdM87",
    "outputId": "9b80b443-5405-448f-b8e4-5cddaec94cd5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(model, Perceptron)\n",
    "assert isinstance(optimizer, torch.optim.Adam)\n",
    "assert optimizer.defaults[\"lr\"] == 0.01\n",
    "\n",
    "assert isinstance(loss_fn, torch.nn.BCELoss)\n",
    "\n",
    "assert isinstance(x_data_static, torch.Tensor)\n",
    "assert x_data_static.shape == (1000, 2)\n",
    "\n",
    "assert isinstance(x_data_static, torch.Tensor)\n",
    "assert y_truth_static.shape == (1000,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Train\n",
    "\n",
    "Set following variables:\n",
    "* `n_epochs` to 100  - number of epochs\n",
    "* `n_batches` to 10 - number of batches\n",
    "* `epoch` to 0 - current epoch number\n",
    "\n",
    "**Train procedure**\n",
    "\n",
    "for each epoch  \n",
    "then for each batch:\n",
    "* make forward step over newly generate batch with parameters `batch_size`, `W` and `B`, \n",
    "* make backward step,\n",
    "* append to `losses` current loss  \n",
    "\n",
    "at the end of batch loop increment `epoch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 7563,
     "status": "ok",
     "timestamp": 1660203339191,
     "user": {
      "displayName": "Branko Žitko",
      "userId": "04777374732866690844"
     },
     "user_tz": -120
    },
    "id": "7vG8dmtJfEiN",
    "outputId": "20b35147-e0e5-46ff-d3d8-b96cbdb573e2",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Evaluate\n",
    "\n",
    "Evaluate model on static data. calculate accuracy, precission, recall and f1. Printout confusion matrix.\n",
    "\n",
    "Note: You can use `scikitlearn.metrics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4. Interspect\n",
    "\n",
    "Determine learnt weights and compare them to `W` and `B` parameters used for generating toy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMCcdqPAojc58imbCCRsEo6",
   "collapsed_sections": [],
   "name": "nlp p02.1 perceptron toy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "358f19b5168dcc2c817c22e8ae2c189228565b53de3b91095ee770a390daccdd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
