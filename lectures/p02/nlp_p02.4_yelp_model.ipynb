{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zojguzq2AuK8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "download_name = \"reviews_with_splits_lite.csv.bz2\"\n",
        "if not os.path.exists(download_name):\n",
        "    import requests\n",
        "    response = requests.get(f\"https://raw.githubusercontent.com/bzitko/nlp_repo/main/lectures/p02/{download_name}\")\n",
        "    with open(download_name, \"wb\") as fp:\n",
        "        fp.write(response.content)\n",
        "    response.close()\n",
        "        \n",
        "name = \"reviews_with_splits_lite.csv\"\n",
        "if not os.path.exists(name):\n",
        "    import bz2\n",
        "    with open(download_name, 'rb') as bzf, open(name, 'wb') as fp:\n",
        "        fp.write(bz2.decompress(bzf.read()))  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-CeYMXmbtG-"
      },
      "source": [
        "# YELP Classify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxFKBmmEEoUA"
      },
      "outputs": [],
      "source": [
        "from argparse import Namespace\n",
        "from collections import Counter\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CQw6LKwiiQg",
        "outputId": "5e3ab09b-73cf-43ed-a021-7fcccebebebe"
      },
      "outputs": [],
      "source": [
        "class Vocabulary(object):\n",
        "    def __init__(self, token_to_idx=None, add_unk=True, unk_token=\"<UNK>\"):\n",
        "        if token_to_idx is None:\n",
        "            token_to_idx = {}\n",
        "        self._token_to_idx = token_to_idx\n",
        "\n",
        "        self._idx_to_token = {idx: token \n",
        "                              for token, idx in self._token_to_idx.items()}\n",
        "        \n",
        "        self._add_unk = add_unk\n",
        "        self._unk_token = unk_token\n",
        "        \n",
        "        self.unk_index = -1\n",
        "        if add_unk:\n",
        "            self.unk_index = self.add_token(unk_token) \n",
        "        \n",
        "        \n",
        "    def to_serializable(self): \n",
        "        return {'token_to_idx': self._token_to_idx, \n",
        "                'add_unk': self._add_unk, \n",
        "                'unk_token': self._unk_token}\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        return cls(**contents)\n",
        "\n",
        "    def add_token(self, token):\n",
        "        if token in self._token_to_idx:\n",
        "            index = self._token_to_idx[token]\n",
        "        else:\n",
        "            index = len(self._token_to_idx)\n",
        "            self._token_to_idx[token] = index\n",
        "            self._idx_to_token[index] = token\n",
        "        return index\n",
        "    \n",
        "    def add_many(self, tokens):\n",
        "        return [self.add_token(token) for token in tokens]\n",
        "\n",
        "    def lookup_token(self, token):\n",
        "        if self.unk_index >= 0:\n",
        "            return self._token_to_idx.get(token, self.unk_index)\n",
        "        else:\n",
        "            return self._token_to_idx[token]\n",
        "\n",
        "    def lookup_index(self, index):\n",
        "        if index not in self._idx_to_token:\n",
        "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
        "        return self._idx_to_token[index]\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<Vocabulary(size={len(self)})>\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._token_to_idx)\n",
        "\n",
        "\n",
        "vocab = Vocabulary()\n",
        "\n",
        "vocab.add_token(\"john\")\n",
        "vocab.add_token(\"john\")\n",
        "vocab.add_token(\"ann\")\n",
        "\n",
        "vocab.lookup_token(\"john\"), vocab.lookup_index(2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfVQ4SbDa_on",
        "outputId": "46b1b2c1-553f-42ec-fa91-3d5e786930cc"
      },
      "outputs": [],
      "source": [
        "class ReviewVectorizer(object):\n",
        "    def __init__(self, review_vocab, rating_vocab):\n",
        "        self.review_vocab = review_vocab\n",
        "        self.rating_vocab = rating_vocab\n",
        "\n",
        "    def vectorize(self, review):\n",
        "        one_hot = np.zeros(len(self.review_vocab), dtype=np.float32)\n",
        "        \n",
        "        for token in review.split(\" \"):\n",
        "            if token not in string.punctuation:\n",
        "                one_hot[self.review_vocab.lookup_token(token)] = 1\n",
        "\n",
        "        return one_hot\n",
        "\n",
        "    @classmethod\n",
        "    def from_dataframe(cls, review_df, cutoff=25):\n",
        "        review_vocab = Vocabulary(add_unk=True)\n",
        "        rating_vocab = Vocabulary(add_unk=False)\n",
        "        \n",
        "        # Add ratings\n",
        "        for rating in sorted(set(review_df.rating)):\n",
        "            rating_vocab.add_token(rating)\n",
        "\n",
        "        # Add top words if count > provided count\n",
        "        word_counts = Counter()\n",
        "        for review in review_df.review:\n",
        "            for word in review.split(\" \"):\n",
        "                if word not in string.punctuation:\n",
        "                    word_counts[word] += 1\n",
        "               \n",
        "        for word, count in word_counts.items():\n",
        "            if count > cutoff:\n",
        "                review_vocab.add_token(word)\n",
        "\n",
        "        return cls(review_vocab, rating_vocab)\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        review_vocab = Vocabulary.from_serializable(contents['review_vocab'])\n",
        "        rating_vocab =  Vocabulary.from_serializable(contents['rating_vocab'])\n",
        "\n",
        "        return cls(review_vocab=review_vocab, rating_vocab=rating_vocab)\n",
        "\n",
        "    def to_serializable(self):\n",
        "        return {'review_vocab': self.review_vocab.to_serializable(),\n",
        "                'rating_vocab': self.rating_vocab.to_serializable()}\n",
        "\n",
        "review_vocab = Vocabulary()\n",
        "review_vocab.add_many(\"john has been there . but he is not john .\".split())\n",
        "\n",
        "rating_vocab = Vocabulary(add_unk=False)\n",
        "rating_vocab.add_many([\"positive\", \"negative\"])\n",
        "\n",
        "vectorizer = ReviewVectorizer(review_vocab, rating_vocab)\n",
        "vectorizer.vectorize(\"but john has not been he .\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKfFfKfZLR7w"
      },
      "source": [
        "### Read Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRDhkO6iHm2j"
      },
      "outputs": [],
      "source": [
        "class ReviewDataset(Dataset):\n",
        "    def __init__(self, review_df, vectorizer):\n",
        "        self.review_df = review_df\n",
        "        self._vectorizer = vectorizer\n",
        "\n",
        "        self.train_df = self.review_df[self.review_df.split=='train']\n",
        "        self.train_size = len(self.train_df)\n",
        "\n",
        "        self.val_df = self.review_df[self.review_df.split=='val']\n",
        "        self.validation_size = len(self.val_df)\n",
        "\n",
        "        self.test_df = self.review_df[self.review_df.split=='test']\n",
        "        self.test_size = len(self.test_df)\n",
        "\n",
        "        self._lookup_dict = {'train': self.train_df,\n",
        "                             'val': self.val_df,\n",
        "                             'test': self.test_df}\n",
        "\n",
        "        self.set_split('train')\n",
        "\n",
        "    @classmethod\n",
        "    def load_dataset_and_make_vectorizer(cls, review_csv):\n",
        "        review_df = pd.read_csv(review_csv)\n",
        "        train_review_df = review_df[review_df.split=='train']\n",
        "        return cls(review_df, ReviewVectorizer.from_dataframe(train_review_df))\n",
        "    \n",
        "    @classmethod\n",
        "    def load_dataset_and_load_vectorizer(cls, review_csv, vectorizer_filepath):\n",
        "        review_df = pd.read_csv(review_csv)\n",
        "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
        "        return cls(review_df, vectorizer)\n",
        "\n",
        "    @staticmethod\n",
        "    def load_vectorizer_only(vectorizer_filepath):\n",
        "        with open(vectorizer_filepath) as fp:\n",
        "            return ReviewVectorizer.from_serializable(json.load(fp))\n",
        "\n",
        "    def save_vectorizer(self, vectorizer_filepath):\n",
        "        with open(vectorizer_filepath, \"w\") as fp:\n",
        "            json.dump(self._vectorizer.to_serializable(), fp)\n",
        "\n",
        "    def get_vectorizer(self):\n",
        "        return self._vectorizer\n",
        "\n",
        "    def set_split(self, split=\"train\"):\n",
        "        self._target_split = split\n",
        "        self._target_df = self._lookup_dict[split]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._target_df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self._target_df.iloc[index]\n",
        "\n",
        "        review_vector = self._vectorizer.vectorize(row.review)\n",
        "\n",
        "        rating_index = self._vectorizer.rating_vocab.lookup_token(row.rating)\n",
        "\n",
        "        return {'x_data': review_vector,\n",
        "                'y_target': rating_index}\n",
        "\n",
        "    def get_num_batches(self, batch_size):\n",
        "        return len(self) // batch_size  \n",
        "    \n",
        "def generate_batches(dataset, batch_size, shuffle=True,\n",
        "                     drop_last=True, device=\"cpu\"):\n",
        "    \n",
        "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
        "                            shuffle=shuffle, drop_last=drop_last)\n",
        "\n",
        "    for data_dict in dataloader:\n",
        "        out_data_dict = {}\n",
        "        for name, tensor in data_dict.items():\n",
        "            out_data_dict[name] = data_dict[name].to(device)\n",
        "        yield out_data_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lPQKo93Oy0v"
      },
      "outputs": [],
      "source": [
        "\n",
        "args = Namespace(\n",
        "    # Data and Path information\n",
        "    frequency_cutoff=25,\n",
        "    model_state_file='model.pth',\n",
        "    review_csv='reviews_with_splits_lite.csv',\n",
        "\n",
        "    # review_csv='data/yelp/reviews_with_splits_full.csv',\n",
        "    save_dir='',\n",
        "    vectorizer_file='vectorizer.json',\n",
        "    \n",
        "    # No Model hyper parameters\n",
        "    # Training hyper parameters\n",
        "    batch_size=128,\n",
        "    early_stopping_criteria=5,\n",
        "    learning_rate=0.001,\n",
        "    num_epochs=100,\n",
        "    seed=1337,\n",
        "    \n",
        "    # Runtime options\n",
        "    catch_keyboard_interrupt=True,\n",
        "    cuda=True,\n",
        "    expand_filepaths_to_save_dir=True,\n",
        "    reload_from_files=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fj6-WVPOO8cx"
      },
      "outputs": [],
      "source": [
        "dataset = ReviewDataset.load_dataset_and_make_vectorizer(args.review_csv)\n",
        "vectorizer = dataset.get_vectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0arywFLH0Sq",
        "outputId": "1e399200-3121-4107-9953-6f9650209fc6"
      },
      "outputs": [],
      "source": [
        "\n",
        "vectorizer.review_vocab\n",
        "len(vectorizer.review_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69,
          "referenced_widgets": [
            "273e7670e85c43e1adfca4d29b8c8ff2",
            "017f7b3f608143a28ac0ea0ce9dc057c",
            "4047dcddc72a4206b8837caa70e3b9ac",
            "f19cf3a075f94fef95c840aec2dcdad5",
            "bcb704239b624eb18b41056dd94c0c1f",
            "8e285e71ef1046fca149eed4df940ed4",
            "23fe11e1f097466dbfd22c45e0c2c0b3",
            "85abf5996edd4af5a05372bcdfe71e83",
            "c0a584ad5e044f7280b0a3b092d4ccc4",
            "bc155ea915064773a0fb51aaa5ccb304",
            "cd46b17049b34814a492b29b0116a0d9"
          ]
        },
        "id": "wt6WLfKQRLeF",
        "outputId": "0d75545f-4d45-4116-f1ea-6c0781987844"
      },
      "outputs": [],
      "source": [
        "dataloader = DataLoader(dataset=dataset)\n",
        "\n",
        "x_data = []\n",
        "y_target = []\n",
        "\n",
        "i = 0\n",
        "for item in tqdm(dataloader):\n",
        "    x_data.append(item[\"x_data\"].squeeze())\n",
        "    y_target.append(item[\"y_target\"].squeeze())\n",
        "\n",
        "    \n",
        "x_data = torch.stack(x_data)\n",
        "y_target = torch.stack(y_target)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70mDk2ctME_k"
      },
      "source": [
        "## Plot data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnXYDPp1WGE9"
      },
      "outputs": [],
      "source": [
        "from sklearn import decomposition\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8ru4AlgVJ5g"
      },
      "outputs": [],
      "source": [
        "pca = decomposition.PCA(n_components=2)\n",
        "pca.fit(x_data)\n",
        "X = pca.transform(x_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "vvx9tCVAVdG7",
        "outputId": "de52252b-f2ce-419e-afff-3e66bd9f12bd"
      },
      "outputs": [],
      "source": [
        "colors = [\"red\" if y_i == 0 else \"blue\" for y_i in y_target]\n",
        "\n",
        "\n",
        "plt.scatter(X[:,0], X[:,1], marker=\".\", s=1, c=colors)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2SGZv7wXzy8"
      },
      "source": [
        "### Model Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xi-ZsiApGXa0"
      },
      "outputs": [],
      "source": [
        "class ReviewClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, num_features):\n",
        "        super(ReviewClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(in_features=num_features, \n",
        "                             out_features=1)\n",
        "\n",
        "    def forward(self, x_in, apply_sigmoid=False):\n",
        "        y_out = self.fc1(x_in).squeeze()\n",
        "        if apply_sigmoid:\n",
        "            y_out = torch.sigmoid(y_out)\n",
        "        return y_out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUb6OLwZBWFs"
      },
      "source": [
        "### Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVOZg4mSZEB2"
      },
      "outputs": [],
      "source": [
        "dataset = ReviewDataset.load_dataset_and_make_vectorizer(args.review_csv)\n",
        "dataset.save_vectorizer(args.vectorizer_file)    \n",
        "vectorizer = dataset.get_vectorizer()\n",
        "\n",
        "classifier = ReviewClassifier(num_features=len(vectorizer.review_vocab))\n",
        "\n",
        "args.device = torch.device(\"cuda\" if args.cuda and torch.cuda.is_available() else \"cpu\")\n",
        "classifier = classifier.to(args.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJFBJBhzCm4h"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5JkMhnJCmhv",
        "outputId": "592a1fc6-173a-41a5-a788-6ed6877aa8ee"
      },
      "outputs": [],
      "source": [
        "loss_func = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
        "                                                 mode='min', factor=0.5,\n",
        "                                                 patience=1)\n",
        "\n",
        "def compute_accuracy(y_pred, y_target):\n",
        "    y_target = y_target.cpu()\n",
        "    y_pred_indices = (torch.sigmoid(y_pred) > 0.5).cpu().long()#.max(dim=1)[1]\n",
        "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
        "    return n_correct / len(y_pred_indices) * 100\n",
        "\n",
        "data = []\n",
        "\n",
        "for epoch_index in range(args.num_epochs):\n",
        "    # TRAIN\n",
        "    dataset.set_split('train')\n",
        "    batch_generator = generate_batches(dataset, \n",
        "                                       batch_size=args.batch_size, \n",
        "                                       device=args.device)\n",
        "    running_loss = 0.0\n",
        "    running_acc = 0.0\n",
        "    classifier.train()\n",
        "\n",
        "    for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            # step 1. zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # step 2. compute the output\n",
        "            y_pred = classifier(x_in=batch_dict['x_data'].float())\n",
        "\n",
        "            # step 3. compute the loss\n",
        "            loss = loss_func(y_pred, batch_dict['y_target'].float())\n",
        "            loss_t = loss.item()\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "            data.append((epoch_index, batch_index, loss_t, running_loss)) \n",
        "\n",
        "            # step 4. use loss to produce gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # step 5. use optimizer to take gradient step\n",
        "            optimizer.step()\n",
        "            # -----------------------------------------\n",
        "            # compute the accuracy\n",
        "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "    \n",
        "    print(f\"Train epoch: {epoch_index+1}/{args.num_epochs} loss: {running_loss:.3f} acc: {running_acc:.3f}\")            \n",
        "\n",
        "    # VAL\n",
        "    dataset.set_split('val')\n",
        "    batch_generator = generate_batches(dataset, \n",
        "                                       batch_size=args.batch_size, \n",
        "                                       device=args.device)\n",
        "    running_loss = 0.\n",
        "    running_acc = 0.\n",
        "    classifier.eval()\n",
        "\n",
        "    for batch_index, batch_dict in enumerate(batch_generator):\n",
        "        # compute the output\n",
        "        y_pred = classifier(x_in=batch_dict['x_data'].float())\n",
        "\n",
        "        # compute the loss\n",
        "        loss = loss_func(y_pred, batch_dict['y_target'].float())\n",
        "        loss_t = loss.item()\n",
        "        running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "        # compute the accuracy\n",
        "        acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
        "        running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "        \n",
        "    print(f\"Valid epoch: {epoch_index+1}/{args.num_epochs} loss: {running_loss:.3f} acc: {running_acc:.3f}\")                 \n",
        "    scheduler.step(running_loss)\n",
        "    new_lr = optimizer.param_groups[0][\"lr\"]\n",
        "    print(\"New lr: {new_lr:.3f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2L9vsbQLKaJ"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kBm2iO2B04Z",
        "outputId": "b9a7322b-381a-4586-96fd-d550e1c1178a"
      },
      "outputs": [],
      "source": [
        "classifier = classifier.to(args.device)\n",
        "\n",
        "dataset.set_split('test')\n",
        "batch_generator = generate_batches(dataset, \n",
        "                                   batch_size=args.batch_size, \n",
        "                                   device=args.device)\n",
        "running_loss = 0.\n",
        "running_acc = 0.\n",
        "classifier.eval()\n",
        "\n",
        "for batch_index, batch_dict in enumerate(batch_generator):\n",
        "    # compute the output\n",
        "    y_pred = classifier(x_in=batch_dict['x_data'].float())\n",
        "\n",
        "    # compute the loss\n",
        "    loss = loss_func(y_pred, batch_dict['y_target'].float())\n",
        "    loss_t = loss.item()\n",
        "    running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "    # compute the accuracy\n",
        "    acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
        "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "\n",
        "print(f\"Test loss: {running_loss} acc: {running_acc}\") "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKWjUTZ0foAd"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnLHhxkKfo9J",
        "outputId": "fed707a7-b47a-40e4-9cef-0a64178e40f6"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"([.,!?])\", r\" \\1 \", text)\n",
        "    text = re.sub(r\"[^a-zA-Z.,!?]+\", r\" \", text)\n",
        "    return text\n",
        "\n",
        "def predict_rating(review, classifier, vectorizer, decision_threshold=0.5):\n",
        "    review = preprocess_text(review)\n",
        "    vectorized_review = torch.tensor(vectorizer.vectorize(review))\n",
        "    result = classifier(vectorized_review.view(1, -1).to(args.device))\n",
        "\n",
        "    probability_value = torch.sigmoid(result).item()\n",
        "\n",
        "    index =  1\n",
        "    if probability_value < decision_threshold:\n",
        "        index = 0\n",
        "\n",
        "    return vectorizer.rating_vocab.lookup_index(index)\n",
        "\n",
        "test_review = \"this is a pretty awesome notebook\"\n",
        "prediction = predict_rating(test_review, classifier, vectorizer)\n",
        "print(f\"{test_review} -> {prediction}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUfbUDkQL5eq"
      },
      "source": [
        "# Interpretability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o26VuMH9LZm_",
        "outputId": "1fd939ae-7251-4428-9079-1290291b68e6"
      },
      "outputs": [],
      "source": [
        "fc1_weights = classifier.fc1.weight.cpu().detach()[0]\n",
        "weights, indices = torch.sort(fc1_weights, dim=0, descending=True)\n",
        "\n",
        "indices = indices.numpy().tolist()\n",
        "\n",
        "\n",
        "# Top 20 words\n",
        "print(\"Influential words in Positive Reviews:\")\n",
        "print(\"--------------------------------------\")\n",
        "for i in range(20):\n",
        "    print(vectorizer.review_vocab.lookup_index(indices[i]))\n",
        "    \n",
        "print(\"====\\n\\n\\n\")\n",
        "\n",
        "# Top 20 negative words\n",
        "print(\"Influential words in Negative Reviews:\")\n",
        "print(\"--------------------------------------\")\n",
        "indices.reverse()\n",
        "for i in range(20):\n",
        "    print(vectorizer.review_vocab.lookup_index(indices[i]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Caj4YogjL-EY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n"
          ]
        }
      ],
      "source": [
        "for i in range(40):\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.13 ('nlp')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "358f19b5168dcc2c817c22e8ae2c189228565b53de3b91095ee770a390daccdd"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "017f7b3f608143a28ac0ea0ce9dc057c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e285e71ef1046fca149eed4df940ed4",
            "placeholder": "​",
            "style": "IPY_MODEL_23fe11e1f097466dbfd22c45e0c2c0b3",
            "value": "100%"
          }
        },
        "23fe11e1f097466dbfd22c45e0c2c0b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "273e7670e85c43e1adfca4d29b8c8ff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_017f7b3f608143a28ac0ea0ce9dc057c",
              "IPY_MODEL_4047dcddc72a4206b8837caa70e3b9ac",
              "IPY_MODEL_f19cf3a075f94fef95c840aec2dcdad5"
            ],
            "layout": "IPY_MODEL_bcb704239b624eb18b41056dd94c0c1f"
          }
        },
        "4047dcddc72a4206b8837caa70e3b9ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85abf5996edd4af5a05372bcdfe71e83",
            "max": 39200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c0a584ad5e044f7280b0a3b092d4ccc4",
            "value": 39200
          }
        },
        "85abf5996edd4af5a05372bcdfe71e83": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e285e71ef1046fca149eed4df940ed4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc155ea915064773a0fb51aaa5ccb304": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcb704239b624eb18b41056dd94c0c1f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0a584ad5e044f7280b0a3b092d4ccc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd46b17049b34814a492b29b0116a0d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f19cf3a075f94fef95c840aec2dcdad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc155ea915064773a0fb51aaa5ccb304",
            "placeholder": "​",
            "style": "IPY_MODEL_cd46b17049b34814a492b29b0116a0d9",
            "value": " 39200/39200 [00:23&lt;00:00, 3060.72it/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
